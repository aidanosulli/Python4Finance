{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "e134e05457d34029b6460cd73bbf1ed73f339b5b6d98c95be70b69eba114fe95"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": "        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Provides ways to work with large multidimensional arrays\n",
    "import numpy as np \n",
    "# Allows for further data manipulation and analysis\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt # Plotting\n",
    "import matplotlib.dates as mdates # Styling dates\n",
    "%matplotlib inline\n",
    "\n",
    "# pip install numpy\n",
    "# conda install -c anaconda pandas\n",
    "# conda install -c conda-forge matplotlib\n",
    "\n",
    "import datetime as dt # For defining dates\n",
    "\n",
    "import time\n",
    "\n",
    "# In Powershell Prompt : conda install -c conda-forge multitasking\n",
    "# pip install -i https://pypi.anaconda.org/ranaroussi/simple yfinance\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "# To show all your output File -> Preferences -> Settings Search for Notebook\n",
    "# Notebook Output Text Line Limit and set to 100\n",
    "\n",
    "# Used for file handling like deleting files\n",
    "import os\n",
    "\n",
    "# conda install -c conda-forge cufflinks-py\n",
    "# conda install -c plotly plotly\n",
    "import cufflinks as cf\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Make Plotly work in your Jupyter Notebook\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# Use Plotly locally\n",
    "cf.go_offline()\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# New Imports\n",
    "# Used to get data from a directory\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "source": [
    "# Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/aidanosullivan/Desktop/Python4Finance/Wilshire_Stocks/\"\n",
    "\n",
    "# Start end date defaults\n",
    "S_DATE = \"2017-02-01\"\n",
    "E_DATE = \"2022-12-06\"\n",
    "S_DATE_DT = pd.to_datetime(S_DATE)\n",
    "E_DATE_DT = pd.to_datetime(E_DATE)"
   ]
  },
  {
   "source": [
    "# Get Dataframe from CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a dataframe from the CSV file, changes index to date and returns it\n",
    "def get_stock_df_from_csv(ticker):\n",
    "    \n",
    "    # Try to get the file and if it doesn't exist issue a warning\n",
    "    try:\n",
    "        df = pd.read_csv(PATH + ticker + '.csv', index_col=0)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File Doesn't Exist\")\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "source": [
    "# Get all stocks downloaded in List"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "files = [x for x in listdir(PATH) if isfile(join(PATH, x))]\n",
    "tickers = [os.path.splitext(x)[0] for x in files]\n",
    "tickers\n",
    "tickers.remove('.DS_Store') # MacOS Only\n",
    "tickers.sort()\n",
    "len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A', 'AA', 'AAL', 'AAME', 'AAN', 'AAOI', 'AAON', 'AAP', 'AAPL', 'AAT']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "source": [
    "# Add daily returns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift provides the value from the previous day\n",
    "# NaN is displayed because there was no previous day price for the 1st calculation\n",
    "def add_daily_return_to_df(df):\n",
    "    df['daily_return'] = (df['Close'] / df['Close'].shift(1)) - 1\n",
    "    # Save data to a CSV file\n",
    "    # df.to_csv(PATH + ticker + '.csv')\n",
    "    return df  "
   ]
  },
  {
   "source": [
    "# Add Cumulative Returns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cum_return_to_df(df):\n",
    "    df['cum_return'] = (1 + df['daily_return']).cumprod()\n",
    "    # df.to_csv(PATH + ticker + '.csv')\n",
    "    return df"
   ]
  },
  {
   "source": [
    "# Add Bollinger Bands\n",
    "\n",
    "Bollinger Bands plot 2 lines using a moving average and the standard deviation defines how far apart the lines are. They also are used to define if prices are to high or low. When bands tighten it is believed a sharp price move in some direction. Prices tend to bounce off of the bands which provides potential market actions.\n",
    "\n",
    "A strong trend should be noted if the price moves outside the band. If prices go over the resistance line it is in overbought territory and if it breaks through support it is a sign of an oversold position."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will add a middle band (20 days), upper band (20 days + 1.96 std),\n",
    "# and lower band (20 days - 1.96 std)\n",
    "def add_bollinger_bands(df):\n",
    "    df['middle_band'] = df['Close'].rolling(window=20).mean()\n",
    "    df['upper_band'] = df['middle_band'] + 1.96 * df['Close'].rolling(window=20).std()\n",
    "    df['lower_band'] = df['middle_band'] - 1.96 * df['Close'].rolling(window=20).std()\n",
    "    # df.to_csv(PATH + ticker + '.csv')\n",
    "    return df"
   ]
  },
  {
   "source": [
    "# Add Ichimoku Data to Dataframe\n",
    "\n",
    "The Ichimoku (One Look) is considered an all in one indicator. It provides information on momentum, support and resistance. It is made up of 5 lines. If you are a short term trader you create 1 minute or 6 hour. Long term traders focus on day or weekly data.\n",
    "\n",
    "Conversion Line (Tenkan-sen) : Represents support, resistance and reversals. Used to measure short term trends.\n",
    "Baseline (Kijun-sen) : Represents support, resistance and confirms trend changes. Allows you to evaluate the strength of medium term trends. Called the baseline because it lags the price.\n",
    "Leading Span A (Senkou A) : Used to identify future areas of support and resistance\n",
    "Leading Span B (Senkou B) : Other line used to identify suture support and resistance\n",
    "Lagging Span (Chikou) : Shows possible support and resistance. It is used to confirm signals obtained from other lines.\n",
    "Cloud (Kumo) : Space between Span A and B. Represents the divergence in price evolution.\n",
    "Formulas\n",
    "\n",
    "Lagging Span = Price shifted back 26 periods\n",
    "Base Line = (Highest Value in period + Lowest value in period)/2 (26 Sessions)\n",
    "Conversion Line = (Highest Value in period + Lowest value in period)/2 (9 Sessions)\n",
    "Leading Span A = (Conversion Value + Base Value)/2 (26 Sessions)\n",
    "Leading Span B = (Conversion Value + Base Value)/2 (52 Sessions)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_Ichimoku(df):\n",
    "    # Conversion\n",
    "    hi_val = df['High'].rolling(window=9).max()\n",
    "    low_val = df['Low'].rolling(window=9).min()\n",
    "    df['Conversion'] = (hi_val + low_val) / 2\n",
    "\n",
    "    # Baseline\n",
    "    hi_val2 = df['High'].rolling(window=26).max()\n",
    "    low_val2 = df['Low'].rolling(window=26).min()\n",
    "    df['Baseline'] = (hi_val2 + low_val2) / 2\n",
    "\n",
    "    # Spans\n",
    "    df['SpanA'] = ((df['Conversion'] + df['Baseline']) / 2).shift(26)\n",
    "    hi_val3 = df['High'].rolling(window=52).max()\n",
    "    low_val3 = df['Low'].rolling(window=52).min()\n",
    "    df['SpanB'] = ((hi_val3 + low_val3) / 2).shift(26)\n",
    "    df['Lagging'] = df['Close'].shift(-26)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "source": [
    "# Add Daily, Cumulative Bollinger Bands & Ichimoku to Dataframes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on : A\n",
      "Working on : AA\n",
      "Working on : AAL\n",
      "Working on : AAME\n",
      "Working on : AAN\n",
      "Working on : AAOI\n",
      "Working on : AAON\n",
      "Working on : AAP\n",
      "Working on : AAPL\n",
      "Working on : AAT\n"
     ]
    }
   ],
   "source": [
    "for x in tickers:\n",
    "    try:\n",
    "        print(\"Working on :\", x)\n",
    "        new_df = get_stock_df_from_csv(x)\n",
    "        new_df = add_daily_return_to_df(new_df)\n",
    "        new_df = add_cum_return_to_df(new_df)\n",
    "        new_df = add_bollinger_bands(new_df)\n",
    "        new_df = add_Ichimoku(new_df)\n",
    "        new_df.to_csv(PATH + x + '.csv')\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is always better to test your results using one stock\n",
    "# try:\n",
    "#     print(\"Working on :\", \"A\")\n",
    "#     new_df = get_stock_df_from_csv(\"A\")\n",
    "#     new_df = add_daily_return_to_df(new_df)\n",
    "#     new_df = add_cum_return_to_df(new_df)\n",
    "#     new_df = add_bollinger_bands(new_df)\n",
    "#     new_df = add_Ichimoku(new_df)\n",
    "#     new_df.to_csv(PATH + 'A' + '.csv')\n",
    "# except Exception as ex:\n",
    "#     print(ex)"
   ]
  }
 ]
}